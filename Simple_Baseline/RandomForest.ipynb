{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0c75302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f285ee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering and resampling\n",
    "import os, glob, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Audio feature extractor\n",
    "def extract_embedding(path, sr=22050, n_mfcc=13, n_mels=64):\n",
    "    y, _ = librosa.load(path, sr=sr, mono=True)\n",
    "\n",
    "    # keyword-only calls\n",
    "    mfcc     = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    mel      = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    logmel   = librosa.power_to_db(mel)\n",
    "    zcr      = librosa.feature.zero_crossing_rate(y=y)\n",
    "    rms      = librosa.feature.rms(y=y)\n",
    "    cent     = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "\n",
    "    def pool(feat):\n",
    "        return np.hstack([feat.mean(axis=1), feat.std(axis=1)])\n",
    "\n",
    "    # concatenate pooled stats\n",
    "    embedding = np.hstack([\n",
    "        pool(mfcc),        # 13*2 dims\n",
    "        pool(logmel),      # n_mels*2 dims\n",
    "        pool(contrast),    # 7*2 dims\n",
    "        pool(zcr),         # 1*2 dims\n",
    "        pool(rms),         # 1*2 dims\n",
    "        pool(cent),        # 1*2 dims\n",
    "    ])\n",
    "\n",
    "    return embedding\n",
    "\n",
    "\n",
    "# 2. Load labels from Excel\n",
    "label_excel = \"C:/Users/jimmy/Documents/Tài liệu/vital docs/Side Project/Resp/COPD.xlsx\"\n",
    "\n",
    "df_labels   = pd.read_excel(label_excel)  \n",
    "# Expect two columns: \"subject_id\" (e.g. \"H002\") and \"severity\" (e.g. \"COPD1\")\n",
    "df_labels[\"Patient_ID\"] = df_labels[\"Patient ID\"].astype(str)\n",
    "\n",
    "# Label encoder for severity\n",
    "le = LabelEncoder()\n",
    "df_labels[\"y_enc\"] = le.fit_transform(df_labels[\"Diagnosis\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "282c2d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-Clip CV F1: 0.412978253254843\n",
      "Per-Clip Test Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       COPD0       0.50      0.50      0.50        14\n",
      "       COPD1       0.19      0.25      0.21        12\n",
      "       COPD2       0.21      0.24      0.22        17\n",
      "       COPD3       0.30      0.18      0.22        17\n",
      "       COPD4       0.52      0.54      0.53        41\n",
      "\n",
      "    accuracy                           0.39       101\n",
      "   macro avg       0.34      0.34      0.34       101\n",
      "weighted avg       0.39      0.39      0.38       101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 2.1 Build X (paths) and y (labels) per clip\n",
    "audio_dir = \"C:/Users/jimmy/Documents/Tài liệu/vital docs/Side Project/Resp/RespiratoryDatabase@TR\"\n",
    "wav_paths = glob.glob(os.path.join(audio_dir, \"H*_*.wav\"))\n",
    "\n",
    "X_paths, y = [], []\n",
    "for p in wav_paths:\n",
    "    fname = os.path.basename(p)\n",
    "    subj  = fname.split(\"_\")[0]           # e.g. \"H002\"\n",
    "    row   = df_labels[df_labels.Patient_ID  == subj]\n",
    "    if row.empty:\n",
    "        continue\n",
    "    X_paths.append(p)\n",
    "    y.append(int(row.y_enc.iloc[0]))\n",
    "\n",
    "X_paths = np.array(X_paths)\n",
    "y       = np.array(y)\n",
    "\n",
    "# 2.2 Split train/test\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X_paths, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 2.3 Pipeline: feature → SMOTE → scale → RF\n",
    "pipe_clip = ImbPipeline([\n",
    "    (\"feat\", FunctionTransformer(\n",
    "        lambda paths: np.vstack([extract_embedding(p) for p in paths]),\n",
    "        validate=False\n",
    "    )),\n",
    "    (\"smote\", SMOTE(random_state=42)),      # now allowed\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"clf\", RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# 2.4 CV & eval\n",
    "cv_scores = cross_val_score(pipe_clip, X_tr, y_tr, cv=5, scoring=\"f1_weighted\")\n",
    "\n",
    "print(\"Per-Clip CV F1:\", cv_scores.mean())\n",
    "\n",
    "pipe_clip.fit(X_tr, y_tr)\n",
    "y_pred = pipe_clip.predict(X_te)\n",
    "print(\"Per-Clip Test Report:\\n\", classification_report(y_te, y_pred,\n",
    "                                                      target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec8004d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-Subject CV weighted F1: 0.2965367965367965\n",
      "Per-Subject Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       COPD0       0.00      0.00      0.00         1\n",
      "       COPD1       0.00      0.00      0.00         1\n",
      "       COPD2       1.00      0.50      0.67         2\n",
      "       COPD3       0.50      1.00      0.67         1\n",
      "       COPD4       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.56         9\n",
      "   macro avg       0.50      0.45      0.44         9\n",
      "weighted avg       0.72      0.56      0.60         9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jimmy\\Documents\\Tài liệu\\vital docs\\Side Project\\Resp\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jimmy\\Documents\\Tài liệu\\vital docs\\Side Project\\Resp\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\jimmy\\Documents\\Tài liệu\\vital docs\\Side Project\\Resp\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# 1. Audio feature extractor (keyword-only API)\n",
    "def extract_embedding(path, sr=22050, n_mfcc=13, n_mels=64):\n",
    "    y, _ = librosa.load(path, sr=sr, mono=True)\n",
    "    mfcc     = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    mel      = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
    "    logmel   = librosa.power_to_db(mel)\n",
    "    zcr      = librosa.feature.zero_crossing_rate(y=y)\n",
    "    rms      = librosa.feature.rms(y=y)\n",
    "    cent     = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "\n",
    "    def pool(feat):\n",
    "        return np.hstack([feat.mean(axis=1), feat.std(axis=1)])\n",
    "\n",
    "    return np.hstack([\n",
    "        pool(mfcc),        # 13→26\n",
    "        pool(logmel),      # n_mels→2*n_mels\n",
    "        pool(contrast),    # 7→14\n",
    "        pool(zcr),         # 1→2\n",
    "        pool(rms),         # 1→2\n",
    "        pool(cent),        # 1→2\n",
    "    ])  # ~174 dims\n",
    "\n",
    "# 2. Load subject‐level labels from Excel\n",
    "label_excel = \"C:/Users/jimmy/Documents/Tài liệu/vital docs/Side Project/Resp/COPD.xlsx\"\n",
    "df_labels   = pd.read_excel(label_excel)\n",
    "# Expect columns: \"subject_id\" (e.g. \"H002\"), \"severity\" (e.g. \"COPD1\")\n",
    "df_labels[\"Patient_ID\"] = df_labels[\"Patient ID\"].astype(str)\n",
    "\n",
    "# Encode string severities to integers\n",
    "le = LabelEncoder()\n",
    "df_labels[\"y_enc\"] = le.fit_transform(df_labels[\"Diagnosis\"])\n",
    "\n",
    "# 3. Build per-subject feature matrix\n",
    "audio_dir = \"C:/Users/jimmy/Documents/Tài liệu/vital docs/Side Project/Resp/RespiratoryDatabase@TR\"\n",
    "subjects  = df_labels[\"Patient_ID\"].tolist()\n",
    "\n",
    "X_subj = []\n",
    "y_subj = []\n",
    "\n",
    "for subj in subjects:\n",
    "    # find all 12 positions for this subject\n",
    "    pattern = os.path.join(audio_dir, f\"{subj}_*.wav\")\n",
    "    files   = glob.glob(pattern)\n",
    "    if not files:\n",
    "        continue\n",
    "\n",
    "    # extract embeddings for each clip\n",
    "    embs = [extract_embedding(f) for f in files]\n",
    "    embs = np.vstack(embs)\n",
    "\n",
    "    # mean-pool across positions\n",
    "    subj_emb = embs.mean(axis=0)\n",
    "\n",
    "    X_subj.append(subj_emb)\n",
    "    y_subj.append(int(df_labels.loc[df_labels.Patient_ID == subj, \"y_enc\"].iloc[0]))\n",
    "\n",
    "X_subj = np.array(X_subj)\n",
    "y_subj = np.array(y_subj)\n",
    "\n",
    "# 4. Train/test split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X_subj, y_subj, test_size=0.2, stratify=y_subj, random_state=42\n",
    ")\n",
    "\n",
    "# 5. Build and run the imbalanced-learn pipeline\n",
    "pipe_subj = ImbPipeline([\n",
    "    (\"smote\", SMOTE(k_neighbors=1, random_state=42)),\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"clf\", RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# 5a. Cross-validation F1\n",
    "cv_scores = cross_val_score(pipe_subj, X_tr, y_tr, cv=3, scoring=\"f1_weighted\")\n",
    "print(\"Per-Subject CV weighted F1:\", cv_scores.mean())\n",
    "\n",
    "# 5b. Final fit & evaluation\n",
    "pipe_subj.fit(X_tr, y_tr)\n",
    "y_pred = pipe_subj.predict(X_te)\n",
    "print(\"Per-Subject Test Report:\")\n",
    "print(classification_report(y_te, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f0a2135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-Clip CV F1: 0.47531556603165653\n",
      "Per-Clip Test Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       COPD0       0.35      0.43      0.39        14\n",
      "       COPD1       0.42      0.42      0.42        12\n",
      "       COPD2       0.35      0.35      0.35        17\n",
      "       COPD3       0.23      0.29      0.26        17\n",
      "       COPD4       0.61      0.49      0.54        41\n",
      "\n",
      "    accuracy                           0.42       101\n",
      "   macro avg       0.39      0.40      0.39       101\n",
      "weighted avg       0.44      0.42      0.43       101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "import os, glob\n",
    "\n",
    "# 2.1 Build X (paths) and y (labels) per clip\n",
    "audio_dir = \"C:/Users/jimmy/Documents/Tài liệu/vital docs/Side Project/Resp/RespiratoryDatabase@TR\"\n",
    "wav_paths = glob.glob(os.path.join(audio_dir, \"H*_*.wav\"))\n",
    "\n",
    "X_paths, y = [], []\n",
    "for p in wav_paths:\n",
    "    fname = os.path.basename(p)\n",
    "    subj  = fname.split(\"_\")[0]           # e.g. \"H002\"\n",
    "    row   = df_labels[df_labels.Patient_ID  == subj]\n",
    "    if row.empty:\n",
    "        continue\n",
    "    X_paths.append(p)\n",
    "    y.append(int(row.y_enc.iloc[0]))\n",
    "\n",
    "X_paths = np.array(X_paths)\n",
    "y       = np.array(y)\n",
    "\n",
    "# 2.2 Split train/test\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X_paths, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 2.3 Pipeline: feature → SMOTE → scale → RF\n",
    "pipe_clip = ImbPipeline([\n",
    "    (\"feat\", FunctionTransformer(\n",
    "        lambda paths: np.vstack([extract_embedding(p) for p in paths]),\n",
    "        validate=False\n",
    "    )),\n",
    "    (\"smote\", SMOTE(random_state=42)),      # now allowed\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# 2.4 CV & eval\n",
    "cv_scores = cross_val_score(pipe_clip, X_tr, y_tr, cv=5, scoring=\"f1_weighted\")\n",
    "\n",
    "print(\"Per-Clip CV F1:\", cv_scores.mean())\n",
    "\n",
    "pipe_clip.fit(X_tr, y_tr)\n",
    "y_pred = pipe_clip.predict(X_te)\n",
    "print(\"Per-Clip Test Report:\\n\", classification_report(y_te, y_pred,\n",
    "                                                      target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "059e70e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-Clip CV F1: 0.2685694568038984\n",
      "Per-Clip Test Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       COPD0       0.32      0.43      0.36        14\n",
      "       COPD1       0.21      0.50      0.30        12\n",
      "       COPD2       0.25      0.41      0.31        17\n",
      "       COPD3       0.15      0.12      0.13        17\n",
      "       COPD4       0.46      0.15      0.22        41\n",
      "\n",
      "    accuracy                           0.27       101\n",
      "   macro avg       0.28      0.32      0.27       101\n",
      "weighted avg       0.32      0.27      0.25       101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "import os, glob\n",
    "\n",
    "# 2.1 Build X (paths) and y (labels) per clip\n",
    "audio_dir = \"C:/Users/jimmy/Documents/Tài liệu/vital docs/Side Project/Resp/RespiratoryDatabase@TR\"\n",
    "wav_paths = glob.glob(os.path.join(audio_dir, \"H*_*.wav\"))\n",
    "\n",
    "X_paths, y = [], []\n",
    "for p in wav_paths:\n",
    "    fname = os.path.basename(p)\n",
    "    subj  = fname.split(\"_\")[0]           # e.g. \"H002\"\n",
    "    row   = df_labels[df_labels.Patient_ID  == subj]\n",
    "    if row.empty:\n",
    "        continue\n",
    "    X_paths.append(p)\n",
    "    y.append(int(row.y_enc.iloc[0]))\n",
    "\n",
    "X_paths = np.array(X_paths)\n",
    "y       = np.array(y)\n",
    "\n",
    "# 2.2 Split train/test\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X_paths, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 2.3 Pipeline: feature → SMOTE → scale → RF\n",
    "pipe_clip = ImbPipeline([\n",
    "    (\"feat\", FunctionTransformer(\n",
    "        lambda paths: np.vstack([extract_embedding(p) for p in paths]),\n",
    "        validate=False\n",
    "    )),\n",
    "    (\"smote\", SMOTE(random_state=42)),      # now allowed\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"clf\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# 2.4 CV & eval\n",
    "cv_scores = cross_val_score(pipe_clip, X_tr, y_tr, cv=5, scoring=\"f1_weighted\")\n",
    "\n",
    "print(\"Per-Clip CV F1:\", cv_scores.mean())\n",
    "\n",
    "pipe_clip.fit(X_tr, y_tr)\n",
    "y_pred = pipe_clip.predict(X_te)\n",
    "print(\"Per-Clip Test Report:\\n\", classification_report(y_te, y_pred,\n",
    "                                                      target_names=le.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
